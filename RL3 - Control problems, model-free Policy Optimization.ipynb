{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class 3: Control problems, model-free Policy Optimization.**\n",
    "\n",
    "1. [Everything you need to know](#everything)\n",
    "2. [General view on policy optimization: Generalized Policy Iteration and Actor-Critic architectures](#GPI)\n",
    "3. [Online problems, the exploration vs. exploitation dilemma](#online)\n",
    "    1. [SARSA](#sarsa)\n",
    "    2. [Q-learning](#qlearning)\n",
    "    3. [Going further with SARSA and Q-learning](#further)\n",
    "4. [Interactive problems](#interactive)\n",
    "5. [Offline problems, focussing on the critic alone](#offline)\n",
    "    1. [Fitted Q-iteration](#fqi)\n",
    "    2. [Least Squares Policy Iteration](#lspi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"everything\"></a>Everything you need to know\n",
    "\n",
    "Everything you should remember after this session.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<ul>\n",
    "<li> Generalized Policy Iteration: perform sample-based policy evaluation and policy improvement, directly from samples (not from the model anymore), converge to $Q^*$ and $\\pi^*$\n",
    "<li> Actor-critic architecture: the actor chooses an action based on the current state and the information provided by the critic, while the critic constantly aims at learning relevant things in order to help the actor decide (value functions for example, or an approximate model).\n",
    "<li>A GLIE actor guarantees that, as $t\\rightarrow\\infty$, 1) all state-action pairs $(s,a)$ are visited infinitely often for $Q$-updates of the critic and 2) the actor's policy $\\pi$ becomes $Q$-greedy.\n",
    "<li>SARSA. Initialize : in $s$, choose (*actor*) $a$ using $Q$, then repeat:\n",
    "<ol>\n",
    "<li> Observe $r$, $s'$\n",
    "<li> Choose $a'$ (<i>GLIE actor<i>) using $Q$\n",
    "<li> Temporal difference: $\\delta=r+\\gamma Q(s',a') - Q(s,a)$\n",
    "<li> Update $Q$: $Q(s,a) \\leftarrow Q(s,a) + \\alpha \\delta$\n",
    "<li> $s\\leftarrow s'$, $a\\leftarrow a'$\n",
    "</ol>\n",
    "<li>Q-learning.\n",
    "<ol>\n",
    "<li> In $s$, choose $a$ (<i>GLIE actor<i>)\n",
    "<li> Observe $r$, $s'$\n",
    "<li> Temporal difference: $\\delta=r+\\gamma \\max_{a'} Q(s',a') - Q(s,a)$\n",
    "<li> Update $Q$: $Q(s,a) \\leftarrow Q(s,a) + \\alpha \\delta$\n",
    "<li> $s\\leftarrow s'$\n",
    "</ol>\n",
    "<li> Fitted Q-iteration (offline learning). For $i=1$ to $N$:\n",
    "<ol>\n",
    "<li> For each sample $(s,a,r,s')$, define $(x,y)$ with:<br>\n",
    "$x = (s,a)$<br>\n",
    "$y = r + \\gamma \\max_{a'} Q_{i-1}(s',a')$<br>\n",
    "Call $\\mathcal{T}$ the training set $\\left\\{(x,y)\\right\\}$\n",
    "<li> $Q_i$ = fit_model$(\\mathcal{T})$\n",
    "</ol>\n",
    "<li> Least Squares Policy Iteration (LSPI) uses the LSTD$Q$ (Least Squares Temporal Differences on $Q$ functions) procedure to approximate the $Q$ function of the current policy, using a set of feature functions $\\varphi$, then replaces the current policy with the $Q$-greedy policy and iterates until convergence.\n",
    "<li> LSTD$Q$ (incremental version):<br>\n",
    "$\\tilde{B} = \\frac{1}{\\delta}I$ with $\\delta$ a small positive value.<br>\n",
    "$\\tilde{b} = 0$<br>\n",
    "For each $(s,a,r,s') \\in \\mathcal{D}$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{B} \\leftarrow \\tilde{B} - \\frac{B \\varphi(s,a) \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T B}{1 + \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T B \\varphi(s,a)} $<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{b} \\leftarrow \\tilde{b} + \\varphi(s,a) r$<br>\n",
    "return $w_\\pi = \\tilde{B} b$\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Of course, all this seems very obscure right now and the block above will only serve as a reminder when you re-open the notebook later. We will introduce every concept intuitively and progessively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"gpi\"></a>General view on policy optimization: Generalized Policy Iteration and Actor-Critic architectures\n",
    "\n",
    "Remember how we went from Policy Iteration (figure below) to Asynchronous Policy Iteration?\n",
    "<img src=\"images/policyiteration.png\"></img>\n",
    "\n",
    "Now recall the principle of Asynchronous Policy Iteration. If we consider the two elementary operations:\n",
    "- Bellman backup on $Q$: $Q(s,a) \\leftarrow r(s,a) + \\gamma \\sum\\limits_{s'} p(s'|s,a) Q(s',\\pi(s'))$\n",
    "- Bellman backup on $\\pi$: $\\pi(s) \\leftarrow \\arg\\max_{a} Q(s,a)$\n",
    "\n",
    "Then, as long as every state and every action is visited infinitely often for Bellman backups on $Q$ or $\\pi$, the sequences of $Q_n$ and $\\pi_n$ converge to $Q^*$ and $\\pi^*$.\n",
    "\n",
    "Value Iteration: in each state, one update of $Q$ and one improvement of $\\pi$.<br>\n",
    "Policy Iteration: update $Q$ in all states until convergence, then update $\\pi$ in all states.\n",
    "\n",
    "**Generalized Policy Iteration** is the case where one has two interacting processes: policy evaluation and policy improvement, directly from samples (not from the model anymore). If these processes converge to their respective targets, then Generalized Policy Iteration converges to $Q^*$ and $\\pi^*$. Model-free policy evaluation can take many forms: indirect RL, Monte Carlo evaluations, TD methods...\n",
    "\n",
    "This leads to the definition of the general **actor-critic architectures** (excerpt from **Algorithms for Reinforcement Learning** by C. Szepesvari):\n",
    "\n",
    "<img src=\"images/actor-critic.png\"  style=\"width: 500px;\"></img>\n",
    "\n",
    "In such architectures, an *actor* chooses an action based on the current state and the information provided by the *critic*, while the *critic* constantly aims at learning relevant things in order to help the *actor* decide (value functions for example, or an approximate model).\n",
    "\n",
    "Almost all Reinforcement Learning algorithms fall into an actor-critic architecture. The following sections separate the search for optimal policies / value functions into two distinct contexts:\n",
    "<ul>\n",
    "<li> Online interaction. The actor needs to balance exploration of new state-action pairs with the exploitation of those which are already known to be good (in order to guide the agent along reward-providing trajectories and to refine the knowledge of the value function around these trajectories). The critic aims at providing the best evaluation of state-action pairs to the actor. In this context, we derive two algorithms:\n",
    "<ul>\n",
    "<li>SARSA, where the critic evaluates the current policy being applied.\n",
    "<li>Q-learning, where the critic evaluates the optimal policy.<br>\n",
    "</ul>\n",
    "In particular, online learning is characterized by the fact that the agent chooses the action to perform, but is constrained by the state dynamics and thus does not choose the states to sample. One can think of this case as the direct interaction with an environment.\n",
    "<li> Interactive problems. These only differ from the online case by the fact that both sampled states and actions can be controled by the learning process. Think of this case as one where one has a simulator and can choose to reset it to any state before deciding on the action to undertake.\n",
    "<li> Offline policy search. In this case, there simply is no actor and the problem boils down to designing a critic that provides $Q^*$. For this problem, we explore two generalizations of Value Iteration and Policy Iterations, respectively:\n",
    "<ul>\n",
    "<li>Fitted Q-Iteration\n",
    "<li>Least Squares Policy Iteration\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"online\"></a>Online problems, the exploration vs. exploitation dilemma\n",
    "\n",
    "In the class on value estimation problems, we introduced temporal differences algorithms such as TD(0), so we have a way to evaluate policies. But now, we are not looking for $V^\\pi$ anymore (or $Q^\\pi$), but for $Q^*$. Let's recall TD(0) on $Q$ functions. Given a sample $(s,a,r,s')$:\n",
    "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left( r + \\gamma Q(s',\\pi(s')) - Q(s,a) \\right)$$\n",
    "Recall that for this update to converge, we need samples for all state-action pairs $(s,a)$.\n",
    "\n",
    "Using TD(0) (or a Monte Carlo estimator), we could easily design an approximate policy iteration algorithm that evaluates $\\pi$ for a certain time, yielding a value function $Q$, then replaces $\\pi$ with the $Q$-greedy policy and starts over. So the key question becomes knowing when to switch from evaluation of $\\pi$ to improvement. As we have seen in Generalized Policy Iteration, we can interleave those two processes.\n",
    "\n",
    "For an agent interacting with a new, unknown environment, let's first learn the $Q$-function of a given policy $\\pi$. The key problem is to insure all state-action pairs will be sampled. To do this, we can make an **ergodocity** assumption on our MDP, that is we can suppose that each state is reachable from any other (non-terminal) state with non-zero probability. Therefore, acting randomly insures exploration of all state-action pairs.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Let's implement that on the policy that always goes right in the FrozenLake environment.\n",
    "<ul>\n",
    "<li> We will start by using the class on MDPs to obtain the true value of $Q^\\pi$.\n",
    "<li> We will also reproduce the TD(0) estimation of $V^\\pi$ from the class on value estimation.\n",
    "<li> Then we will use it to initialize $Q$ and implement the TD(0) update that converges to $Q^\\pi$.\n",
    "</ul>\n",
    "As before, to keep things simple, we set $\\alpha=0.001$ and we take $\\gamma=0.9$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:25:57.438498Z",
     "start_time": "2019-01-15T16:25:56.795158Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:25:57.446163Z",
     "start_time": "2019-01-15T16:25:57.441096Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')\n",
    "actions = {fl.LEFT: '\\u2190', fl.DOWN: '\\u2193', fl.RIGHT: '\\u2192', fl.UP: '\\u2191'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:25:58.421989Z",
     "start_time": "2019-01-15T16:25:57.447789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtrue:\n",
      " [[0.013 0.013 0.013 0.011]\n",
      " [0.007 0.012 0.012 0.016]\n",
      " [0.031 0.023 0.027 0.012]\n",
      " [0.008 0.008 0.    0.008]\n",
      " [0.024 0.02  0.019 0.009]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.064 0.056 0.064 0.008]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.02  0.059 0.049 0.064]\n",
      " [0.105 0.161 0.146 0.071]\n",
      " [0.23  0.211 0.186 0.063]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.134 0.257 0.301 0.211]\n",
      " [0.313 0.59  0.556 0.479]\n",
      " [0.    0.    0.    0.   ]]\n",
      "number of iterations: 18\n",
      "Vtrue:\n",
      " [0.013 0.012 0.027 0.    0.019 0.    0.064 0.    0.049 0.146 0.186 0.\n",
      " 0.    0.301 0.556 0.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Policy definition and parameters\n",
    "pi0 = fl.RIGHT*np.ones((env.observation_space.n),dtype=np.int)\n",
    "gamma = 0.9\n",
    "alpha = 0.001\n",
    "\n",
    "# Model based evaluation\n",
    "def policy_Qeval_iter(pi, epsilon, max_iter):\n",
    "    Q1 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    Q2 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    residuals = np.zeros((max_iter))\n",
    "    for i in range(max_iter):\n",
    "        for x in range(env.observation_space.n):\n",
    "            for a in range(env.action_space.n):\n",
    "                Q2[x][a] = 0\n",
    "                outcomes = env.unwrapped.P[x][a]\n",
    "                for o in outcomes:\n",
    "                    p = o[0]\n",
    "                    y = o[1]\n",
    "                    r = o[2]\n",
    "                    Q2[x][a] += p * (r + gamma*Q1[y][pi[y]])\n",
    "        residuals[i] = np.max(np.abs(Q2-Q1))\n",
    "        Q1[:] = Q2\n",
    "        if residuals[i]<epsilon:\n",
    "            residuals = residuals[:i+1]\n",
    "            break\n",
    "    return Q1, residuals\n",
    "\n",
    "Qpi0true, residuals = policy_Qeval_iter(pi0,1e-4,10000)\n",
    "print(\"Qtrue:\\n\", Qpi0true)\n",
    "print(\"number of iterations:\", residuals.size)\n",
    "plt.plot(residuals)\n",
    "plt.figure()\n",
    "plt.semilogy(residuals)\n",
    "\n",
    "Vpi0true = np.zeros((env.observation_space.n))\n",
    "for x in range(env.observation_space.n):\n",
    "    Vpi0true[x] = Qpi0true[x][pi0[x]]\n",
    "print(\"Vtrue:\\n\", Vpi0true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:26:18.101666Z",
     "start_time": "2019-01-15T16:25:58.424386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013 0.012 0.027 0.    0.018 0.    0.062 0.    0.049 0.138 0.185 0.\n",
      " 0.    0.289 0.557 0.   ]\n",
      "[0.013 0.012 0.027 0.    0.019 0.    0.064 0.    0.049 0.146 0.186 0.\n",
      " 0.    0.301 0.556 0.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TD(0) evaluation of Vpi\n",
    "def TD_Veval(pi, max_steps, V=None, Vtrue=None):\n",
    "    if(V is None):\n",
    "        V = np.zeros((env.observation_space.n))\n",
    "    error = np.zeros((max_steps))\n",
    "    x = env.reset()\n",
    "    for t in range(max_steps):\n",
    "        y,r,d,_ = env.step(pi[x])\n",
    "        V[x] = V[x] + alpha * (r+gamma*V[y]-V[x])\n",
    "        if(Vtrue is not None):\n",
    "            error[t] = np.max(np.abs(V-Vtrue))\n",
    "        if d==True:\n",
    "            x = env.reset()\n",
    "        else:\n",
    "            x=y\n",
    "    return V, error\n",
    "\n",
    "Vpi0, error = TD_Veval(pi0, 1000000, Vtrue=Vpi0true)\n",
    "print(Vpi0)\n",
    "print(Vpi0true)\n",
    "plt.plot(error)\n",
    "plt.figure()\n",
    "plt.semilogy(error);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:27:46.432293Z",
     "start_time": "2019-01-15T16:26:18.105579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0.023489054157189604\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TD(0) evaluation of Qpi\n",
    "Qpi0 = np.transpose(np.tile(Vpi0, (4,1)))\n",
    "\n",
    "def TD_Qeval(pi, max_steps, Q=None, Qtrue=None):\n",
    "    error = np.zeros((max_steps))\n",
    "    if (Q is None):\n",
    "        Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    x = env.reset()\n",
    "    for t in range(max_steps):\n",
    "        a = np.random.randint(4)\n",
    "        y,r,d,_ = env.step(a)\n",
    "        Q[x][a] = Q[x][a] + alpha * (r+gamma*Q[y][pi[y]]-Q[x][a])\n",
    "        if(Qtrue is not None):\n",
    "            error[t] = np.max(np.abs(Q-Qtrue))\n",
    "        if d==True:\n",
    "            x = env.reset()\n",
    "        else:\n",
    "            x=y\n",
    "    return Q, error\n",
    "\n",
    "Qpi0, error = TD_Qeval(pi0,3000000,Qpi0,Qpi0true)\n",
    "print(\"Max error:\", np.max(np.abs(Qpi0-Qpi0true)))\n",
    "plt.plot(error)\n",
    "plt.figure()\n",
    "plt.semilogy(error);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a way of evaluating $Q^\\pi$. But we're interested in $Q^*$. Let's use the idea of Generalized Policy Iteration and include, inside the TD(0) loop above, the policy improvement phase $\\pi(s)\\leftarrow \\arg\\max_a Q(s,a)$. This means that at each time step, instead of evaluating the temporal difference for a fixed policy $\\pi$, we evaluate a policy that is $Q$-greedy. According to the convergence property of Generalized Policy Iteration, this should converge to $Q^*$. But then again, the policy applied by our agent remains totally random so it clearly does not converge to $\\pi^*$. To solve this issue we introduce the notion of **Greedy in the limit of infinite exploration** (GLIE) actor:<br>\n",
    "<br>\n",
    "<div class=\"alert alert-success\"><b>Greedy in the limit of infinite exploration</b> (GLIE) actor:<br>\n",
    "A GLIE actor guarantees that:<br>\n",
    "- All state-action pairs $(s,a)$ are visited infinitely often for updates of $Q$, as $t\\rightarrow\\infty$:\n",
    "$$\\lim_{t\\rightarrow\\infty} count_t(s,a) = \\infty$$\n",
    "- As $t\\rightarrow\\infty$ the actor becomes $Q$-greedy, that is:\n",
    "$$\\lim_{t\\rightarrow\\infty} \\pi_t(a|s) = \\mathbb{1}\\left(a = \\arg\\max_{\\hat{a}} Q(s,\\hat{a})\\right)$$\n",
    "</div>\n",
    "\n",
    "An example of GLIE actor is the so-called $\\epsilon$-greedy exploration strategy that uniformly picks a non-greedy action with probability $\\epsilon$:\n",
    "$$\\pi_t(a|s) = \\left\\{\\begin{array}{ll}1-\\epsilon_t & \\textrm{if }a=\\arg\\max_{\\hat{a}} Q(s,\\hat{a})\\\\\n",
    "\\frac{\\epsilon_t}{|A|-1} & \\textrm{otherwise} \\end{array}\\right.$$\n",
    "With a parameter $\\epsilon_t>0$ that goes to zero as $t$ tends to $\\infty$, one obtains a GLIE actor.\n",
    "\n",
    "GLIE actors (or policies) enforce the limits of the **exploration vs. exploitation compromise**. As long as actors respect the GLIE properties, actor-critic architectures fall within the convergence properties of Generalized Policy Iteration.\n",
    "\n",
    "With this last definition, we have all the ingredients to define algorithms that evolve to an optimal behaviour.\n",
    "\n",
    "<a href=\"#GLIEremark\" data-toggle=\"collapse\"> A remark</a><br>\n",
    "<div id=\"GLIEremark\" class=\"collapse\">\n",
    "You might have noticed that the totally random policy we applied in the TD(0) update was a very naive choice. Even if all states are reachable from anywhere in the state space (ergodicity property), they might not all be visited with the same frequency and therefore the convergence to $Q^\\pi$ might be delayed because of this uniform exploration strategy.<br>\n",
    "<br>\n",
    "The same remark applies to $\\epsilon$-greedy exploration strategies that often start with $\\epsilon=1$ and let it slowly decrease towards zero. These strategies don't account for the actual *visitation frequencies* of state-action pairs. In some states it might be good to keep a strong exploration probability because they actually have been seldom visited, while in other states, a faster decrease is desirable. This links also to the question of *value propagation* that was underpinned by the asynchronous value iteration remarks in the class on MDPs.<br>\n",
    "<br>\n",
    "The point here is to notice that $\\epsilon$-greedy is a simple, very naive exploration strategy that fits within the GLIE requirements but that much better exploration policies are possible by taking the current state into account (contextual exploration) or by using the values of the temporal difference (prioritized experience replay) and the $Q$ estimate (Boltzmann policies, $E^3$ or $R_{max}$ strategies) for instance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sarsa\"></a>SARSA\n",
    "\n",
    "The key idea behind the SARSA algorithm is to build a critic that constantly tries to evaluate the value $Q$ of the actor's policy $\\pi$, and an actor that tends to be greedy with respect to this critic. The algorithm is written:\n",
    "\n",
    "<div class=\"alert alert-success\"><b>SARSA</b><br>\n",
    "In $s$, choose (*actor*) $a$ using $Q$, then repeat:\n",
    "<ol>\n",
    "<li> Observe $r$, $s'$\n",
    "<li> Choose $a'$ (*GLIE actor*) using $Q$\n",
    "<li> Temporal difference: $\\delta=r+\\gamma Q(s',a') - Q(s,a)$\n",
    "<li> Update $Q$: $Q(s,a) \\leftarrow Q(s,a) + \\alpha \\delta$\n",
    "<li> $s\\leftarrow s'$, $a\\leftarrow a'$\n",
    "</ol>\n",
    "SARSA converges if the actor is GLIE and if $\\alpha$ respects the Robbins-Monro conditions.\n",
    "</div>\n",
    "\n",
    "It is important to note that SARSA is an **on-policy** critic: it constantly evaluates the current $\\pi$... that constantly shifts towards $\\pi^*$ by being $Q$-greedy.\n",
    "\n",
    "The name SARSA comes from the usage of an augmented sample $(s,a,r,s',a')$.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Let's implement an $\\epsilon$-greedy SARSA on the FrozenLake problem.<br>\n",
    "For the decrease of $\\epsilon$ we can opt for a division by 2 every million steps.<br>\n",
    "You can compare with $Q^*$ and $\\pi^*$ obtained during the model-based class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:27:46.472926Z",
     "start_time": "2019-01-15T16:27:46.436359Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0281c21f0bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mVinit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mVstar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVinit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mQstar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_from_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVstar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Model-based policy optimization and a few utility functions\n",
    "\n",
    "def value_iteration(V,epsilon,max_iter):\n",
    "    W = np.copy(V)\n",
    "    residuals = np.zeros((max_iter))\n",
    "    for i in range(max_iter):\n",
    "        for s in range(env.observation_space.n):\n",
    "            Q = np.zeros((env.action_space.n))\n",
    "            for a in range(env.action_space.n):\n",
    "                outcomes = env.unwrapped.P[s][a]\n",
    "                for o in outcomes:\n",
    "                    p  = o[0]\n",
    "                    s2 = o[1]\n",
    "                    r  = o[2]\n",
    "                    Q[a] += p*(r+gamma*V[s2])\n",
    "            W[s] = np.max(Q)\n",
    "            #print(W[s])\n",
    "        residuals[i] = np.max(np.abs(W-V))\n",
    "        #print(\"abs\", np.abs(W-V))\n",
    "        np.copyto(V,W)\n",
    "        if residuals[i]<epsilon:\n",
    "            residuals = residuals[:i+1]\n",
    "            break\n",
    "    return V, residuals\n",
    "\n",
    "def Q_from_V(V):\n",
    "    Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    for s in range(env.observation_space.n):\n",
    "        for a in range(env.action_space.n):\n",
    "            outcomes = env.unwrapped.P[s][a]\n",
    "            for o in outcomes:\n",
    "                p  = o[0]\n",
    "                s2 = o[1]\n",
    "                r  = o[2]\n",
    "                Q[s,a] += p*(r+gamma*V[s2])\n",
    "    return Q\n",
    "\n",
    "def greedyQpolicy(Q):\n",
    "    pi = np.zeros((env.observation_space.n),dtype=np.int)\n",
    "    for s in range(env.observation_space.n):\n",
    "        pi[s] = np.argmax(Q[s,:])\n",
    "    return pi\n",
    "\n",
    "def to_s(row,col):\n",
    "    return row*env.unwrapped.ncol+col\n",
    "\n",
    "def to_row_col(s):\n",
    "    col = s%env.unwrapped.ncol\n",
    "    row = int((s-col)/env.unwrapped.ncol)\n",
    "    return row,col\n",
    "\n",
    "def print_policy(pi):\n",
    "    for row in range(env.unwrapped.nrow):\n",
    "        for col in range(env.unwrapped.ncol):\n",
    "            print(actions[pi[to_s(row,col)]], end='')\n",
    "        print()\n",
    "    return\n",
    "\n",
    "Vinit = np.zeros((env.observation_space.n))\n",
    "Vstar,residuals = value_iteration(Vinit,1e-4,1000)\n",
    "Qstar = Q_from_V(Vstar)\n",
    "print(actions)\n",
    "print(Vstar)\n",
    "print(Qstar)\n",
    "pi_star = greedyQpolicy(Qstar)\n",
    "print_policy(pi_star)\n",
    "env.render();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:29:13.865310Z",
     "start_time": "2019-01-15T16:27:46.475072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0.051201516785519485\n"
     ]
    }
   ],
   "source": [
    "# Let's restart from Qpi0\n",
    "Qsarsa = Qpi0\n",
    "max_steps = 5000000\n",
    "\n",
    "def epsilon_greedy(Q, s, epsilon):\n",
    "    a = np.argmax(Q[s,:])\n",
    "    if(np.random.rand()<=epsilon): # random action\n",
    "        aa = np.random.randint(env.action_space.n-1)\n",
    "        if aa==a:\n",
    "            a=env.action_space.n-1\n",
    "        else:\n",
    "            a=aa\n",
    "    return a\n",
    "\n",
    "# SARSA\n",
    "count = np.zeros((env.observation_space.n,env.action_space.n)) # to track update frequencies\n",
    "epsilon = 1\n",
    "x = env.reset()\n",
    "a = epsilon_greedy(Qsarsa,x,epsilon)\n",
    "for t in range(max_steps):\n",
    "    if((t+1)%1000000==0):\n",
    "        epsilon = epsilon/2\n",
    "    y,r,d,_ = env.step(a)\n",
    "    aa = epsilon_greedy(Qsarsa,y,epsilon)\n",
    "    Qsarsa[x][a] = Qsarsa[x][a] + alpha * (r+gamma*Qsarsa[y][aa]-Qsarsa[x][a])\n",
    "    count[x][a] += 1\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "        a = epsilon_greedy(Qsarsa,x,epsilon)\n",
    "    else:\n",
    "        x=y\n",
    "        a = aa\n",
    "\n",
    "# SARSA's final value function and policy\n",
    "print(\"Max error:\", np.max(np.abs(Qsarsa-Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:29:13.883954Z",
     "start_time": "2019-01-15T16:29:13.867163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final epsilon: 0.03125\n",
      "Greedy SARSA policy:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Difference between pi_sarsa and pi_star (recall that there are several optimal policies):\n",
      "[0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      "Max difference in value between pi_sarsa and pi_star: 0.003177892849937747\n",
      "Min difference in value between pi_sarsa and pi_star: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Final epsilon:\", epsilon)\n",
    "pi_sarsa = greedyQpolicy(Qsarsa)\n",
    "print(\"Greedy SARSA policy:\")\n",
    "print_policy(pi_sarsa)\n",
    "print(\"Difference between pi_sarsa and pi_star (recall that there are several optimal policies):\")\n",
    "print(pi_sarsa-pi_star)\n",
    "Qpi_sarsa, residuals = policy_Qeval_iter(pi_sarsa,1e-4,10000)\n",
    "print(\"Max difference in value between pi_sarsa and pi_star:\", np.max(np.abs(Qpi_sarsa-Qstar)))\n",
    "print(\"Min difference in value between pi_sarsa and pi_star:\", np.min(np.abs(Qpi_sarsa-Qstar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same remark as for TD(0) holds: with a better exploration strategy, the convergence to Qstar could be much more efficient. We can see that some states have been visited (and updated) way more often than others. Let's plot the exploration map for each action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:29:14.260181Z",
     "start_time": "2019-01-15T16:29:13.885635Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "count_map = np.zeros((env.unwrapped.nrow, env.unwrapped.ncol, env.action_space.n))\n",
    "for a in range(env.action_space.n):\n",
    "    for x in range(env.observation_space.n):\n",
    "        row,col = to_row_col(x)\n",
    "        count_map[row, col, a] = count[x,a]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4)\n",
    "for a in range(env.action_space.n):\n",
    "    name = \"a = \" + actions[a]\n",
    "    axs[a].set_title(name)\n",
    "    axs[a].imshow(np.log(count_map[:,:,a]+1), interpolation='nearest')\n",
    "    #print(\"a=\", a, \":\", sep='')\n",
    "    #print(count_map[:,:,a])\n",
    "plt.show()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"qlearning\"></a>Q-learning\n",
    "\n",
    "It is somehow regretable that the convergence of $Q$ to $Q^*$ in SARSA depends on the decrease schedule of $\\epsilon$ (because SARSA always tries to evaluate the current policy). One could wish for an algorithm that tries to infer $Q^*$ independently of the actor's policy. In other words, one could wish for an **off-policy** algorithm that converges to $Q^*$. That's Q-learning.\n",
    "\n",
    "At each time step, Q-learning aims at evaluating what would be the optimal $Q$-function, independently of the policy applied. Thus, its target is $Q^*$ rather than $Q^\\pi$. To do this, it simply changes the TD update of SARSA into:\n",
    "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left[r + \\gamma \\max_{a'} Q(s',a') - Q(s,a)\\right]$$\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Q-learning</b><br>\n",
    "Repeat:\n",
    "<ol>\n",
    "<li> In $s$, choose $a$ (*GLIE actor*)\n",
    "<li> Observe $r$, $s'$\n",
    "<li> Temporal difference: $\\delta=r+\\gamma \\max_{a'} Q(s',a') - Q(s,a)$\n",
    "<li> Update $Q$: $Q(s,a) \\leftarrow Q(s,a) + \\alpha \\delta$\n",
    "<li> $s\\leftarrow s'$\n",
    "</ol>\n",
    "Q-learning converges if the actor is GLIE and if $\\alpha$ respects the Robbins-Monro conditions.\n",
    "</div>\n",
    "\n",
    "The policy applied is not the target of the TD(0) update anymore: we have replaced $Q(s',a')$ by $\\max_{a'} Q(s',a')$, so if $Q=Q^*$ we are effectively evaluating an optimal policy. While SARSA was the sample-based implementation of an estimator for the **evaluation equation** (from the MDP class), Q-learning is the implementation of an estimator for the **optimality equation**.\n",
    "\n",
    "It is important to note that Q-learning is an **off-policy** critic: its target is independent of the policy applied by the actor (but of course the samples $(s,a,r,s')$ depend on the actor).<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Let's implement an $\\epsilon$-greedy Q-learning on the FrozenLake problem.<br>\n",
    "As in the previous exercice, for the decrease of $\\epsilon$ we can opt for a division by 2 every million steps.<br>\n",
    "You can compare with $Q^*$ and $\\pi^*$ obtained during the model-based class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:31:15.004243Z",
     "start_time": "2019-01-15T16:29:14.262895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0.00965406652423717\n"
     ]
    }
   ],
   "source": [
    "# Let's restart from Qpi0\n",
    "Qql = Qpi0\n",
    "max_steps = 5000000\n",
    "\n",
    "# Q-learning\n",
    "count = np.zeros((env.observation_space.n,env.action_space.n)) # to track update frequencies\n",
    "epsilon = 1\n",
    "x = env.reset()\n",
    "for t in range(max_steps):\n",
    "    if((t+1)%1000000==0):\n",
    "        epsilon = epsilon/2\n",
    "    a = epsilon_greedy(Qql,x,epsilon)\n",
    "    y,r,d,_ = env.step(a)\n",
    "    Qql[x][a] = Qql[x][a] + alpha * (r+gamma*np.max(Qql[y][:])-Qql[x][a])\n",
    "    count[x][a] += 1\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y\n",
    "\n",
    "# Q-learning's final value function and policy\n",
    "print(\"Max error:\", np.max(np.abs(Qql-Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:31:15.027094Z",
     "start_time": "2019-01-15T16:31:15.006978Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final epsilon: 0.03125\n",
      "Greedy Q-learning policy:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Difference between pi_ql and pi_star (recall that there are several optimal policies):\n",
      "[0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      "Max difference in value between pi_sarsa and pi_star: 9.613535775387927e-05\n",
      "Min difference in value between pi_sarsa and pi_star: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Final epsilon:\", epsilon)\n",
    "pi_ql = greedyQpolicy(Qql)\n",
    "print(\"Greedy Q-learning policy:\")\n",
    "print_policy(pi_ql)\n",
    "print(\"Difference between pi_ql and pi_star (recall that there are several optimal policies):\")\n",
    "print(pi_ql-pi_star)\n",
    "Qpi_ql, residuals = policy_Qeval_iter(pi_ql,1e-4,10000)\n",
    "print(\"Max difference in value between pi_sarsa and pi_star:\", np.max(np.abs(Qpi_ql-Qstar)))\n",
    "print(\"Min difference in value between pi_sarsa and pi_star:\", np.min(np.abs(Qpi_ql-Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:31:15.656076Z",
     "start_time": "2019-01-15T16:31:15.028855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "count_map = np.zeros((env.unwrapped.nrow, env.unwrapped.ncol, env.action_space.n))\n",
    "for a in range(env.action_space.n):\n",
    "    for x in range(env.observation_space.n):\n",
    "        row,col = to_row_col(x)\n",
    "        count_map[row, col, a] = count[x,a]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4)\n",
    "for a in range(env.action_space.n):\n",
    "    name = \"a = \" + actions[a]\n",
    "    axs[a].set_title(name)\n",
    "    axs[a].imshow(np.log(count_map[:,:,a]+1), interpolation='nearest')\n",
    "    #print(\"a=\", a, \":\", sep='')\n",
    "    #print(count_map[:,:,a])\n",
    "plt.show()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"further\"></a>Going further with SARSA and Q-learning\n",
    "\n",
    "The exercices below will help you go further with SARSA and Q-learning (you can skip this part if this is the first time you read this notebook). [Link to next part](#offline)\n",
    "<div class=\"alert alert-warning\"><b>Exercices:</b><br>\n",
    "<ul>\n",
    "<li><b>Context-dependent exploration</b><br>\n",
    "Can you implement an $(s,a)$-dependent $\\epsilon$-greedy exploration strategy (by using the `count` table introduced earlier for instance)?\n",
    "<li><b>Heuristic initialization on $Q$</b><br>\n",
    "For Q-learning, can you think of an initialization of $Q$ that would be better than plain zeros (for example by exploiting the maximum 1-step reward $r_{max}$)? One that, for instance, would drive the exploration towards unvisited states?\n",
    "<li><b>Reward shaping</b><br>\n",
    "Did you notice that falling into a hole brings no penalty? If we introduced a $-1$ reward for falling into a hole, would it change the optimal policy?\n",
    "<li><b>SARSA($\\lambda$)</b><br>\n",
    "SARSA is an on-policy method and we've seen that so is TD($\\lambda$) so it seems rather straightforward to implement a SARSA($\\lambda$) algorithm that, hopefully, will have better convergence properties than plain SARSA.\n",
    "<li><b>$Q(\\lambda)$</b><br>\n",
    "This time it is not as straightfoward to derive a $Q(\\lambda)$ algorithm from TD($\\lambda$), precisely because TD($\\lambda$) evaluates the policy being applied and not another one. Can you imagine a way to still perform $Q(\\lambda)$ updates? An answer is found in Watkins's thesis that introduces Q-learning in 1989. For a more recent approach and other references, see Sutton et al, <b>A new Q($\\lambda$) with interim forward view and Monte Carlo equivalence</b>, 2014)\n",
    "<li><b>SARSA and $Q$-learning with linear value function approximation</b><br>\n",
    "Can you implement an approximate version of SARSA and $Q$-learning with linear Q-function approximation $Q(s,a)=\\theta^T\\varphi(s,a)$?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#going\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"going\" class=\"collapse\">\n",
    "TODO\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"interactive\"></a>Interactive problems\n",
    "\n",
    "The previous section focused on **online learning**, where the agent could decide, at each step, what action to take (thus making a compromise between exploration and exploitation) but suffered the consequences of this action on the next step with no control over this next states.\n",
    "\n",
    "However, in many cases, our agent does not interact with the real world but with a simulator, which we can reset to a predefined state. This case, where the agent controls both the state $s$ and the action $a$ in which it queries samples, is called **interactive learning** and online problems are a specific subset of interactive learning problems.\n",
    "\n",
    "In interactive problems, the exploration vs. exploitation compromise turn to an **active learning** problem. There, the agent should decide to sample more into promising parts or into unexplored parts of $S\\times A$.\n",
    "\n",
    "Currently, this notebook does not cover the case of interactive problems, which will be the focus of the class on Monte Carlo Tree Search. However, the reader is invited to read the excellent discussion in section 4.1 and 4.2 of the **[Algorithms in Reinforcement Learning](https://sites.ualberta.ca/~szepesva/RLBook.html)** book by Csaba Szepesvari (draft freely available online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"offline\"></a>Offline problems, focussing on the critic alone\n",
    "\n",
    "If this is the first time you read this notebook, you can skip this part. However, bear in mind that the approaches described below carry many insights as to the construction of efficient critics and, even if they are not as fashionable as Deep Q-learning approaches today, they still represent an important part of the RL literature.\n",
    "\n",
    "We now turn our attention to offline problems. These are problems where someone provides the agent with a data set $\\mathcal{D}=\\left\\{(s,a,r,s')\\right\\}$ but allows no interaction with the environment. These are also called *batch learning problems*. The agent is still required to search for an optimal policy.\n",
    "\n",
    "Obviously, in this setting, there is no *actor* anymore, since there is no interaction with the environment. The question then becomes: can we still learn an optimal policy / value function from this data set?\n",
    "\n",
    "Obviously, we could try to infer the underlying MDP's transition and reward models from $\\mathcal{D}$ and then solve the optimality equation. In the next two sections, we propose two algorithms that respectively approximate Value Iteration and Policy Iteration with the samples from $\\mathcal{D}$.\n",
    "\n",
    "Since there is no exploration in offline RL, it defines a rather specific class of problems for which the curse of dimensionality is less of an issue than in online or interactive RL. Here, the samples set is known from the start and we should make the best possible use of it, with no particular hope that we could get a better coverage of the state-action space. Of course, this translates directly to our ability to generalize well the finite set of samples at our disposal to a value function that covers the full state-action space and therefore, it moves the exploration problem towards a *representation* problem, commonly known in **Supervized Learning** (in particular via the bias-variance tradeoff).\n",
    "\n",
    "An interesting feature about methods that solve offline RL problems is that they are necessarily off-policy. However, they might still be sensitive to the distribution of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"fqi\"></a>Fitted Q-iteration\n",
    "\n",
    "Recall the idea of Value Iteration. In every state we performed the Bellman backup:\n",
    "$$V(s) \\leftarrow \\max_{a} r(s,a) + \\gamma\\sum_{s'\\in S} p(s'|s,a) V(s')$$\n",
    "We can write the $Q$-function version of Value Iteration, which we call $Q$-iteration:\n",
    "$$Q(s,a) \\leftarrow r(s,a) + \\gamma \\sum_{s'\\in S} p(s'|s,a) \\max_{a'} Q(s',a')$$\n",
    "\n",
    "The online version of this update leads to the Q-learning algorithm. The offline version will require a function approximator and is called **fitted Q-iteration**.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-success\"><b>Fitted Q-iteration</b><br>\n",
    "Given a regression method \"fit_model\" and an initial $Q_0=0$.<br>\n",
    "For $i=1$ to $N$:\n",
    "<ul>\n",
    "<li> For each sample $(s,a,r,s')$ in $\\mathcal{D}$, define $(x,y)$ with:<br>\n",
    "$x = (s,a)$<br>\n",
    "$y = r + \\gamma \\max_{a'} Q_{i-1}(s',a')$<br>\n",
    "Call $\\mathcal{T}$ the training set $\\left\\{(x,y)\\right\\}$\n",
    "<li> $Q_i$ = fit_model$(\\mathcal{T})$\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Note that in the tabular case, a straightforward version of fitted Q-iteration boils down to averaging the values of $r + \\gamma \\max_{a'} Q_{i-1}(s',a')$ for all the $(r,s')$ resulting from the same $(s,a)$.\n",
    "\n",
    "Of course, the more expressive \"fit_model\" is, the less error one carries from one iteration to the other. In practice, it is known that fitted Q-iteration might diverge unless some special regressor is used. Kernel smoothing, tree-based methods or neural networks can be good candidates for the implementation of such algorithms. In the cases where fitted Q-iteration converges, it does so to a neighborhood of the optimal $Q^*$.<br>\n",
    "<br>\n",
    "A general sufficient condition for the convergence of fitted Q-iteration is to use *averagers*; these are functions that can be decomposed as $Q(s,a)=\\sum\\limits_{i} \\theta_i \\varphi_i(s,a)$ with the property that $\\forall (s,a), \\sum\\limits_{i} \\varphi_i(s,a) = 1$. Note that *kernel-based methods* are averagers (*tree-based methods* being a specific case of kernel-based methods, with constant 0/1 kernels).<br>\n",
    "<br>\n",
    "A good reference on fitted Q-iteration is the article **[Tree based batch mode Reinforcement Learning](http://www.jmlr.org/papers/volume6/ernst05a/ernst05a.pdf)** by Ernst et al. (2004).<br>\n",
    "An alternative reference, using neural networks instead to tree-based methods is **[Neural Fitted Q-Iteration - first experiences with a data efficient reinforcement learning method](https://pdfs.semanticscholar.org/2820/01869bd502c7917db8b32b75593addfbbc68.pdf)** by Riedmiller (2005).<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Implement a fitted Q-iteration method in the exact tabular case for the FrozenLake problem.<br>\n",
    "The training data will be collected by performing a uniform random walk.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:31:29.801635Z",
     "start_time": "2019-01-15T16:31:15.658726Z"
    }
   },
   "outputs": [],
   "source": [
    "# data generation\n",
    "N=1000000\n",
    "XX = np.zeros((N), dtype=np.int)\n",
    "AA = np.zeros((N), dtype=np.int)\n",
    "RR = np.zeros((N))\n",
    "YY = np.zeros((N), dtype=np.int)\n",
    "count = np.zeros((env.observation_space.n,env.action_space.n)) # to track update frequencies\n",
    "x = env.reset()\n",
    "XX[0] = x\n",
    "for t in range(N):\n",
    "    a = np.random.randint(4)\n",
    "    y,r,d,_ = env.step(a)\n",
    "    XX[t] = x\n",
    "    AA[t] = a\n",
    "    RR[t] = r\n",
    "    YY[t] = y\n",
    "    count[x,a] += 1\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:31:30.146767Z",
     "start_time": "2019-01-15T16:31:29.803759Z"
    }
   },
   "outputs": [],
   "source": [
    "count_map = np.zeros((env.unwrapped.nrow, env.unwrapped.ncol, env.action_space.n))\n",
    "for a in range(env.action_space.n):\n",
    "    for x in range(env.observation_space.n):\n",
    "        row,col = to_row_col(x)\n",
    "        count_map[row, col, a] = count[x,a]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4)\n",
    "for a in range(env.action_space.n):\n",
    "    name = \"a = \" + actions[a]\n",
    "    axs[a].set_title(name)\n",
    "    axs[a].imshow(np.log(count_map[:,:,a]+1), interpolation='nearest')\n",
    "    print(\"a=\", a, \":\", sep='')\n",
    "    print(count_map[:,:,a])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:32:55.380575Z",
     "start_time": "2019-01-15T16:31:30.149444Z"
    }
   },
   "outputs": [],
   "source": [
    "# FQI\n",
    "FQI_steps=20\n",
    "Q_fqi = np.zeros((env.observation_space.n, env.action_space.n, FQI_steps))\n",
    "count = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "for i in range(XX.shape[0]):\n",
    "    count[XX[i], AA[i]] +=1\n",
    "\n",
    "for n in range(1,FQI_steps):\n",
    "    for i in range(XX.shape[0]):\n",
    "        Q_fqi[XX[i], AA[i], n] += RR[i] + gamma * np.max(Q_fqi[YY[i], :, n-1])\n",
    "    for s in range(env.observation_space.n):\n",
    "        for a in range(env.action_space.n):\n",
    "            if(count[s,a]!=0):\n",
    "                Q_fqi[s,a,n] = Q_fqi[s,a,n] / count[s,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:32:55.400389Z",
     "start_time": "2019-01-15T16:32:55.382615Z"
    }
   },
   "outputs": [],
   "source": [
    "pi_fqi = greedyQpolicy(Q_fqi[:,:,FQI_steps-1])\n",
    "print(\"Greedy FQI policy:\")\n",
    "print_policy(pi_fqi)\n",
    "print(\"Difference between pi_fqi and pi_star (recall that there are several optimal policies):\")\n",
    "print(pi_fqi-pi_star)\n",
    "Qpi_fqi, residuals = policy_Qeval_iter(pi_fqi,1e-4,10000)\n",
    "print(\"Max difference in value between pi_fqi and pi_star:\", np.max(np.abs(Qpi_fqi-Qstar)))\n",
    "print(\"Min difference in value between pi_fqi and pi_star:\", np.min(np.abs(Qpi_fqi-Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:32:56.119310Z",
     "start_time": "2019-01-15T16:32:55.402283Z"
    }
   },
   "outputs": [],
   "source": [
    "delta = np.zeros((FQI_steps))\n",
    "for n in range(FQI_steps):\n",
    "    Q, residuals = policy_Qeval_iter(greedyQpolicy(Q_fqi[:,:,n]),1e-4,10000)\n",
    "    delta[n] = np.max(np.abs(Q-Qstar))\n",
    "\n",
    "plt.plot(delta)\n",
    "plt.figure()\n",
    "plt.semilogy(delta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In very large state and action spaces, it might be difficult to obtain samples $(s,a)$ covering efficiently the full $S\\times A$ space. However, supposing that the approximation method for $Q(s,a)$ is robust to non-uniform $(s,a)$-distributions, one can remark that fitted Q-iteration lends itself quite easily to interleaving the data acquisition phase and the value function improvement. Again, this come with no guarantees concerning convergence but can be an advantage in very large state and action spaces.<br>\n",
    "<br>\n",
    "In particular, provided that the database of samples contains enough information about reward providing transitions, it might be interesting to progressively focus the sampling strategy around the last $Q$-greedy policy's state-action distribution. For an example of application of this idea, one can refer to **Clinical data based optimal STI strategies for HIV: a Reinforcement Learning approach** by Ernst et al (2006).<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Implement a modified fitted Q-iteration algorithm that collects new samples at step $n$ by using a $Q_{n-1}$-greedy  $\\epsilon$-greedy policy and adds them to the training database.<br>\n",
    "More precisely, at each enrichment step, add $N$ new samples to the dataset, but only generate $N/10$ of them using $\\epsilon = 1 - \\frac{i}{9}$ for $i\\in [0,9]$.<br>\n",
    "Start with an initial zero $Q$-function.\n",
    "</div>\n",
    "We don't expect to see much of a difference compared to the previous exercice because FrozenLake is just too simple, but we can still do this exercice for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:35:00.089676Z",
     "start_time": "2019-01-15T16:32:56.124605Z"
    }
   },
   "outputs": [],
   "source": [
    "# incremental FQI\n",
    "N=100000\n",
    "XX = np.zeros((0), dtype=np.int)\n",
    "AA = np.zeros((0), dtype=np.int)\n",
    "RR = np.zeros((0))\n",
    "YY = np.zeros((0), dtype=np.int)\n",
    "FQI_steps=20\n",
    "Q_fqi = np.zeros((env.observation_space.n, env.action_space.n, FQI_steps))\n",
    "count = np.zeros((env.observation_space.n,env.action_space.n)) # to track update frequencies\n",
    "for n in range(1,FQI_steps):\n",
    "    print(\"FQI step number\", n)\n",
    "    # data generation\n",
    "    XXX = np.zeros((N), dtype=np.int)\n",
    "    AAA = np.zeros((N), dtype=np.int)\n",
    "    RRR = np.zeros((N))\n",
    "    YYY = np.zeros((N), dtype=np.int)\n",
    "    count2 = np.zeros((env.observation_space.n,env.action_space.n))\n",
    "    epsilon = 1\n",
    "    Nbatch = np.floor(N/10)\n",
    "    x = env.reset()\n",
    "    for i in range(N):\n",
    "        if (i%Nbatch == 0):\n",
    "            epsilon -= 1./9.\n",
    "        a = epsilon_greedy(Q_fqi[:,:,n-1],x,epsilon)\n",
    "        y,r,d,_ = env.step(a)\n",
    "        XXX[i] = x\n",
    "        AAA[i] = a\n",
    "        RRR[i] = r\n",
    "        YYY[i] = y\n",
    "        count2[x,a] += 1\n",
    "        if d==True:\n",
    "            x = env.reset()\n",
    "        else:\n",
    "            x=y\n",
    "    XX = np.append(XX,XXX)\n",
    "    AA = np.append(AA,AAA)\n",
    "    RR = np.append(RR,RRR)\n",
    "    YY = np.append(YY,YYY)\n",
    "    count = count + count2\n",
    "    print(\"number of samples in dataset:\", XX.shape[0])\n",
    "    # Value function computation\n",
    "    for i in range(XX.shape[0]):\n",
    "        Q_fqi[XX[i], AA[i], n] += RR[i] + gamma * np.max(Q_fqi[YY[i], :, n-1])\n",
    "    for s in range(env.observation_space.n):\n",
    "        for a in range(env.action_space.n):\n",
    "            if(count[s,a]!=0):\n",
    "                Q_fqi[s,a,n] = Q_fqi[s,a,n] / count[s,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:35:00.761210Z",
     "start_time": "2019-01-15T16:35:00.092204Z"
    }
   },
   "outputs": [],
   "source": [
    "delta = np.zeros((FQI_steps))\n",
    "for n in range(FQI_steps):\n",
    "    Q, residuals = policy_Qeval_iter(greedyQpolicy(Q_fqi[:,:,n]),1e-4,10000)\n",
    "    delta[n] = np.max(np.abs(Q-Qstar))\n",
    "\n",
    "plt.plot(delta)\n",
    "plt.figure()\n",
    "plt.semilogy(delta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To alleviate the problem of the linearly increasing size of the database in the example above, one could implement, for instance, a uniform random removal over the data set, in order to keep its size bounded. These more advanced tricks and their implications are beyond the scope of this notebook but they give a first flavour of the mini-batches and experience replay tricks that are used in state-of-the-art Deep Reinforcement Learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FrozenLake is a very simple toy problem with (few) discrete states and actions. So the dataset above covers well the full state-action space. But in the general case, the state-action space might be continuous or just too large to sample extensively. So one has to rely on the generalization properties of a regressor.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Let's implement a fitted Q-iteration method using Random Forests (or Extremely Randomized Trees) as a regressor over the (row, column, action) feature space.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:35:12.625813Z",
     "start_time": "2019-01-15T16:35:00.762964Z"
    }
   },
   "outputs": [],
   "source": [
    "# data generation\n",
    "N=1000000\n",
    "XX = np.zeros((N), dtype=np.int)\n",
    "AA = np.zeros((N), dtype=np.int)\n",
    "RR = np.zeros((N))\n",
    "YY = np.zeros((N), dtype=np.int)\n",
    "x = env.reset()\n",
    "XX[0] = x\n",
    "print(\"data generation\")\n",
    "for t in range(N):\n",
    "    a = np.random.randint(4)\n",
    "    y,r,d,_ = env.step(a)\n",
    "    XX[t] = x\n",
    "    AA[t] = a\n",
    "    RR[t] = r\n",
    "    YY[t] = y\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:35:20.008147Z",
     "start_time": "2019-01-15T16:35:12.627611Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor as regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor as regressor\n",
    "\n",
    "# Dataset preparation\n",
    "print(\"dataset preparation\")\n",
    "nb_samples = XX.shape[0]\n",
    "Xregr = np.zeros((nb_samples,3))\n",
    "Yregr = np.zeros((nb_samples))\n",
    "for i in range(nb_samples):\n",
    "    row,col = to_row_col(XX[i])\n",
    "    Xregr[i,0] = row\n",
    "    Xregr[i,1] = col\n",
    "    Xregr[i,2] = AA[i]\n",
    "# X_next_state is a table containing all possible pairs (s',a') ordered as (s0, a0), (s0,a1), (s0,a2), (s1,a0)...\n",
    "# It will be useful to compute max_a Q(s,a)\n",
    "X_next_state = np.zeros((env.action_space.n * nb_samples, 3))\n",
    "index = 0\n",
    "for i in range(nb_samples):\n",
    "    row,col = to_row_col(YY[i])\n",
    "    for a in range(env.action_space.n):\n",
    "        X_next_state[index,0] = row\n",
    "        X_next_state[index,1] = col\n",
    "        X_next_state[index,2] = a\n",
    "        index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.530977Z",
     "start_time": "2019-01-15T16:35:20.010458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tree-based FQI (WARNING, the repeated training of the regressor might be very long)\n",
    "\n",
    "# hack: sink_mask is a vector that is 0 for terminal states and 1 otherwise\n",
    "# it is used to avoid having non-zero values for max_a Q(s,a), for terminal states s\n",
    "sinks = {5,7,11,12,15}\n",
    "sink_mask = np.ones((nb_samples))\n",
    "for i in range(nb_samples):\n",
    "    if (YY[i] in sinks):\n",
    "        sink_mask[i] = 0\n",
    "\n",
    "# FQI\n",
    "FQI_steps=20\n",
    "Qfunctions = []\n",
    "print(\"FQI step 0 - training regressor\")\n",
    "Qfunctions.append(regressor(n_estimators=200))\n",
    "Qfunctions[-1].fit(Xregr,Yregr)\n",
    "for n in range(1,FQI_steps):\n",
    "    print(\"FQI step\", n, end=\" - \")\n",
    "    pred_next_state = Qfunctions[-1].predict(X_next_state)\n",
    "    maxQ2 = np.max((pred_next_state.reshape(nb_samples, env.action_space.n)), axis=1)\n",
    "    maxQ2 = np.multiply(maxQ2,sink_mask)\n",
    "    Yregr = RR + gamma * maxQ2\n",
    "    print(\"training regressor\")\n",
    "    Qfunctions.append(regressor(n_estimators=200))\n",
    "    Qfunctions[-1].fit(Xregr,Yregr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.534154Z",
     "start_time": "2019-01-15T16:25:56.959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build greedy policy\n",
    "pi_fqi = np.zeros((env.observation_space.n),dtype=np.int)\n",
    "for s in range(env.observation_space.n):\n",
    "    Q = np.zeros((env.action_space.n))\n",
    "    row,col = to_row_col(s)\n",
    "    for a in range(env.action_space.n):\n",
    "        xinput = np.array([row,col,a]).reshape((1,3))\n",
    "        Q[a] = Qfunctions[-1].predict(xinput)\n",
    "    pi_fqi[s] = np.argmax(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.536098Z",
     "start_time": "2019-01-15T16:25:56.966Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Greedy FQI policy:\")\n",
    "print_policy(pi_fqi)\n",
    "print(\"Difference between pi_fqi and pi_star (recall that there are several optimal policies):\")\n",
    "print(pi_fqi-pi_star)\n",
    "Qpi_fqi, residuals = policy_Qeval_iter(pi_fqi,1e-4,10000)\n",
    "print(\"Max difference in value between pi_fqi and pi_star:\", np.max(np.abs(Qpi_fqi-Qstar)))\n",
    "print(\"Min difference in value between pi_fqi and pi_star:\", np.min(np.abs(Qpi_fqi-Qstar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#sinkmask\" data-toggle=\"collapse\">Important remark</a><br>\n",
    "<div id=\"sinkmask\" class=\"collapse\">\n",
    "Did you notice the `sink_mask` hack in the code above and its importance?<br>\n",
    "<br>\n",
    "When dealing with environments that have terminal states (such as the holes and the frisbee location here), no transitions will ever be sampled from those states. So a regression method (such as Random Forests) will never see samples starting from $(s,a)$ for a terminal $s$ and therefore will never be informed that it should return zero for any transition starting from $s$. Instead, it will return whatever value it can infer from all the other collected data. But the FQI procedure just ignores that fact: when computing $r+\\gamma \\max_{a'} Q(s',a')$ for terminal $s'$, it will request a scalar value from the regressor that was never informed that it should return value zero. Often, this will result in giving a non-zero value to transitions starting from terminal states and this will bias the resulting value functions and policies. To avoid this phenomenon, we introduced that `sink_mask` vector that zeroes down the $\\max_{a'} Q(s',a')$ term for any terminal $s'$. The regressor is still not informed that transitions from $s'$ are worth zero but at least we don't propagate this error through the iterations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"lspi\"></a>Least Squares Policy Iteration\n",
    "\n",
    "Least Squares Policy Iteration (LSPI) answers the question: can we implement a Policy Iteration method based only on samples and given a linear model for the $Q$-function?\n",
    "\n",
    "Since we are talking about Policy Iteration, the critical step is the evaluation of a given policy.\n",
    "\n",
    "Suppose $Q^\\pi(s,a) = w^T \\varphi(s,a)$. We write $\\Phi$ the matrix of feature evaluations for all pairs $(s,a)$, that is:\n",
    "$$\\Phi = \\left[\\begin{array}{ccc}\\varphi_0(s_0,a_0) & \\cdots & \\varphi_0(s_{|S|},a_{|A|}) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\varphi_K(s_0,a_0) & \\cdots & \\varphi_K(s_{|S|},a_{|A|}) \\end{array}\\right]$$\n",
    "\n",
    "Then, $Q^\\pi = r^\\pi + \\gamma P^\\pi Q^\\pi$ becomes:\n",
    "$$\\Phi w_\\pi = r^\\pi + \\gamma P^\\pi \\Phi w_\\pi$$\n",
    "\n",
    "But $r^\\pi + \\gamma P^\\pi \\Phi w_\\pi$ has no reason to lie within $span(\\varphi)$. So we should consider its projection on $span(\\varphi)$ as illustrated by the figure below.\n",
    "\n",
    "<img src=\"images/projection.png\" style=\"width: 600px;\"></img>\n",
    "\n",
    "The projection operator on $span(\\varphi)$ is $\\Phi\\left(\\Phi^T \\Phi\\right)^{-1} \\Phi^T$. And thus $w_\\pi$ is a solution to:\n",
    "$$\\Phi w_\\pi = \\Phi\\left(\\Phi^T \\Phi\\right)^{-1} \\Phi^T \\left( r^\\pi + \\gamma P^\\pi \\Phi w_\\pi \\right)$$\n",
    "\n",
    "And this system can be solved as (for a proof, see the seminal paper **[Least Squares Policy Iteration](http://www.jmlr.org/papers/volume4/lagoudakis03a/lagoudakis03a.pdf)** by Lagoudakis and Parr in 2003):\n",
    "$$w_\\pi  = \\left[\\Phi^T\\left(\\Phi - \\gamma P^\\pi \\Phi\\right)\\right]^{-1}\\Phi^T r^\\pi$$\n",
    "\n",
    "Let $A = \\Phi^T\\left(\\Phi - \\gamma P^\\pi \\Phi\\right)$ and $b=\\Phi^T  r^\\pi$. We have $w_\\pi = A^{-1}b$ so the question becomes: can we compute $A$ and $b$ from samples?\n",
    "\n",
    "Taking a closer look at $A$ and $b$, we have:\n",
    "$$A = \\sum\\limits_{s\\in S} \\sum\\limits_{a\\in A} \\sum\\limits_{s'\\in S} p(s'|s,a) \\left[ \\varphi(s,a) \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T \\right]$$\n",
    "$$b= \\sum\\limits_{s\\in S} \\sum\\limits_{a\\in A} \\sum\\limits_{s'\\in S} p(s'|s,a) \\left[ \\varphi(s,a) r(s,a,s')\\right]$$\n",
    "\n",
    "And thus $A$ is the sum of many matrices of the form $\\varphi(s,a) \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\varphi(s')) \\right)^T$ and $b$ is the sum of many vectors of the form $\\varphi(s,a) r(s,a,s')$.\n",
    "\n",
    "And so, finally, with $\\mathcal{D}=\\left\\{(s_i,a_i,r_i,s'_i)\\right\\}_{i=1..N}$, $A$ and $b$ can be approximated by:\n",
    "$$A \\approx \\frac{1}{N} \\sum\\limits_{i=1}^N\\left[\\varphi(s_i, a_i)\\left(\\varphi(s_i, a_i) - \\gamma \\varphi(s'_i, \\pi(s'_i))\\right)^T\\right]$$\n",
    "$$b \\approx \\frac{1}{N} \\sum\\limits_{i=1}^N \\left[ \\varphi(s_i,a_i)r_i \\right]$$\n",
    "\n",
    "From these expressions one gets the LSTD$Q$ (Least Squares Temporal Differences on $Q$ functions) algorithm that evaluates policy $\\pi$ given a function basis $\\varphi$:\n",
    "<div class=\"alert alert-success\"><b>LSTD$Q(\\pi,\\varphi)$</b>:<br>\n",
    "$K=\\dim(Im(\\varphi))$<br>\n",
    "$\\tilde{A} = 0_{K\\times K}$<br>\n",
    "$\\tilde{b} = 0_K$<br>\n",
    "For each $(s,a,r,s') \\in \\mathcal{D}$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{A} \\leftarrow \\tilde{A} + \\varphi(s,a) \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{b}\\leftarrow \\tilde{b} + \\varphi(s,a) r$<br>\n",
    "return $w_\\pi = \\tilde{A}^{-1} b$\n",
    "</div>\n",
    "\n",
    "LSTD$Q$ requires the inversion of $\\tilde{A}$, which my not be full rank until a sufficient number of samples have been processed. One way to avoid  such singularities is to initialize $\\tilde{A}$ to a multiple of the identity matrix $\\delta I_K$ for some small positive $\\delta$, instead of $0_{K\\times K}$.\n",
    "\n",
    "This definition of LSTD$Q$ can be improved by using the Sherman-Morrison formula (incremental computation of the inverse $\\tilde{B}$ of $\\tilde{A}$) and the algorithm becomes:\n",
    "<div class=\"alert alert-success\"><b>LSTD$Q(\\pi,\\varphi)$ with incremental inverse computation</b>:<br>\n",
    "$\\tilde{B} = \\frac{1}{\\delta}I$ with $\\delta$ a small positive value.<br>\n",
    "$\\tilde{b} = 0$<br>\n",
    "For each $(s,a,r,s') \\in \\mathcal{D}$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{B} \\leftarrow \\tilde{B} - \\frac{B \\varphi(s,a) \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T B}{1 + \\left( \\varphi(s,a) - \\gamma\\varphi(s',\\pi(s')) \\right)^T B \\varphi(s,a)} $<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{b} \\leftarrow \\tilde{b} + \\varphi(s,a) r$<br>\n",
    "return $w_\\pi = \\tilde{B} b$\n",
    "</div>\n",
    "\n",
    "The time complexity of the algorithm above is far lesser ($O(K^2)$) than the one involving the inversion of $\\tilde{A}$ ($O(K^3)$).\n",
    "\n",
    "LSTD$Q$ as defined above computes the weights of any policy $\\pi$. We will note this operation: $w \\leftarrow$ LSTD$Q$($\\pi,\\varphi$). But we also remark that given a weights vector $w$, computing the weights for the value of the $w^T \\varphi$ -greedy policy requires building $\\tilde{B}$ and $\\tilde{b}$. This computation requires finding the $\\arg\\max_{a'\\in A} w^T\\varphi(s',a')$ in all $s'$ concerned by the updates of $\\tilde{B}$, which can be done on the fly, sample after sample, without explicitly storing the greedy policy. Thus we can define the operation $w' \\leftarrow$ LSTD$Q$($w, \\varphi$) that directly computes the weights $w$ of the policy that is greedy with respect to $w^T\\varphi$.\n",
    "\n",
    "This way, we can evaluate any policy $\\pi$ or any $w^T \\varphi$-greedy policy given the dataset $\\mathcal{D}$. The LSPI algorithm is then simply, given an initial $\\pi_0$:<br>\n",
    "$w' \\leftarrow $ LSTD$Q$($\\pi_0,\\varphi$)<br>\n",
    "Repeat:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $w \\leftarrow w'$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $w' \\leftarrow$ LSTD$Q$($w,\\varphi$)<br>\n",
    "until $\\|w-w'\\|\\leq \\epsilon$<br>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Implement LSTQ$Q$ and LSPI as functions of an initial policy $\\pi$.<br>\n",
    "Since we can (because FrozenLake is very simple), let's use the state-action indicator functions as features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.537859Z",
     "start_time": "2019-01-15T16:25:56.971Z"
    }
   },
   "outputs": [],
   "source": [
    "# features\n",
    "nb_features = env.observation_space.n * env.action_space.n\n",
    "\n",
    "def phi(s,a):\n",
    "    val = np.zeros((env.observation_space.n*env.action_space.n))\n",
    "    index = a*env.observation_space.n + s\n",
    "    val[index] = 1.\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.539385Z",
     "start_time": "2019-01-15T16:25:56.976Z"
    }
   },
   "outputs": [],
   "source": [
    "# LSTDQ\n",
    "def LSTDQ_w(w, XX, AA, RR, YY, gamma, phi):\n",
    "    nb_samples = XX.shape[0]\n",
    "    delta = 1e-5\n",
    "    B = (1/delta)*np.eye(nb_features)\n",
    "    b = np.zeros((nb_features,1))\n",
    "    for i in range(nb_samples):\n",
    "        phi1 = phi(XX[i],AA[i]).reshape((nb_features,1))\n",
    "        Q2 = np.zeros(env.action_space.n)\n",
    "        for a in range(env.action_space.n):\n",
    "            phi2 = phi(YY[i],a)\n",
    "            Q2[a] = np.dot(w,phi2)\n",
    "        a2 = np.argmax(Q2)\n",
    "        phi2 = phi(YY[i],a2).reshape((nb_features,1))\n",
    "        # update B\n",
    "        B = B - ( B @ (phi1 @ (phi1-gamma*phi2).T) @ B ) / (1. + (phi1-gamma*phi2).T @ B @ phi1 )\n",
    "        # update b\n",
    "        b = b + phi1 * RR[i]\n",
    "    return (B @ b).ravel()\n",
    "\n",
    "def LSTDQ_pi(pi, XX, AA, RR, YY, gamma, phi):\n",
    "    nb_samples = XX.shape[0]\n",
    "    delta = 1e-5\n",
    "    B = (1/delta)*np.eye(nb_features)\n",
    "    b = np.zeros((nb_features,1))\n",
    "    for i in range(nb_samples):\n",
    "        phi1 = phi(XX[i],AA[i]).reshape((nb_features,1))\n",
    "        phi2 = phi(YY[i],pi[YY[i]]).reshape((nb_features,1))\n",
    "        # update B\n",
    "        B = B - ( B @ (phi1 @ (phi1-gamma*phi2).T) @ B ) / (1. + (phi1-gamma*phi2).T @ B @ phi1 )\n",
    "        # update b\n",
    "        b = b + phi1 * RR[i]\n",
    "    return (B @ b).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.540803Z",
     "start_time": "2019-01-15T16:25:56.982Z"
    }
   },
   "outputs": [],
   "source": [
    "# data generation\n",
    "N=1000000\n",
    "XX = np.zeros((N), dtype=np.int)\n",
    "AA = np.zeros((N), dtype=np.int)\n",
    "RR = np.zeros((N))\n",
    "YY = np.zeros((N), dtype=np.int)\n",
    "x = env.reset()\n",
    "XX[0] = x\n",
    "print(\"data generation\", end=\" - \")\n",
    "for t in range(N):\n",
    "    a = np.random.randint(4)\n",
    "    y,r,d,_ = env.step(a)\n",
    "    XX[t] = x\n",
    "    AA[t] = a\n",
    "    RR[t] = r\n",
    "    YY[t] = y\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y\n",
    "print(N, \"data points generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.542228Z",
     "start_time": "2019-01-15T16:25:56.988Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSPI\n",
    "pi0 = fl.RIGHT*np.ones((env.observation_space.n), dtype=np.int)\n",
    "max_iterations = 5 # maximum number of iterations for Policy Iteration\n",
    "epsilon = 1e-4\n",
    "w = np.zeros((max_iterations, nb_features))\n",
    "residual = np.zeros((max_iterations))\n",
    "print(\"LSPI iteration number 0 (evaluate first policy)\")\n",
    "w[0,:] = LSTDQ_pi(pi0, XX, AA, RR, YY, gamma, phi)\n",
    "for i in range(1,max_iterations):\n",
    "    print(\"LSPI iteration number,\", i, \"(evaluate greedy policy wrt w)\")\n",
    "    w[i,:] = LSTDQ_w(w[i-1,:], XX, AA, RR, YY, gamma, phi)\n",
    "    residual[i-1] = np.max(np.abs(w[i,:]-w[i-1,:]))\n",
    "    print(\"Residual ||w'-w|| =\", residual[i-1])\n",
    "    if (residual[i-1] < epsilon):\n",
    "        w = w[:i+1,:]\n",
    "        residual = residual[:i]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.543920Z",
     "start_time": "2019-01-15T16:25:56.993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying final results\n",
    "nb_iterations = w.shape[0]\n",
    "\n",
    "def policy_from_w(w, phi):\n",
    "    pi = np.zeros((env.observation_space.n),np.int)\n",
    "    for s in range(env.observation_space.n):\n",
    "        Q = np.zeros((env.action_space.n))\n",
    "        for a in range(env.action_space.n):\n",
    "            Q[a] = np.dot(w,phi(s,a))\n",
    "        pi[s] = np.argmax(Q)\n",
    "    return pi\n",
    "\n",
    "pi_lspi = policy_from_w(w[-1,:],phi)\n",
    "\n",
    "print(\"Finished in\", nb_iterations, \"iterations.\")\n",
    "print(\"Final LSPI policy:\")\n",
    "print_policy(pi_lspi)\n",
    "print(\"Evolution of ||w' - w||:\")\n",
    "val = np.zeros((nb_iterations-1))\n",
    "for i in range(nb_iterations-1):\n",
    "    val[i] = np.max(np.abs(w[i+1,:]-w[i,:]))\n",
    "plt.plot(residual)\n",
    "plt.show()\n",
    "print(\"Difference between pi_lspi and pi_star (recall that there are several optimal policies):\")\n",
    "print(pi_lspi-pi_star)\n",
    "Qpi_lspi, residuals = policy_Qeval_iter(pi_lspi,1e-4,10000)\n",
    "print(\"Max difference in value between pi_lspi and pi_star:\", np.max(np.abs(Qpi_lspi-Qstar)))\n",
    "print(\"Min difference in value between pi_lspi and pi_star:\", np.min(np.abs(Qpi_lspi-Qstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:37:44.545595Z",
     "start_time": "2019-01-15T16:25:56.998Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Convergence to pi_star:\")\n",
    "delta = np.zeros((nb_iterations))\n",
    "for n in range(nb_iterations):\n",
    "    Q, residuals = policy_Qeval_iter(policy_from_w(w[n,:],phi),1e-4,10000)\n",
    "    delta[n] = np.max(np.abs(Q-Qstar))\n",
    "\n",
    "plt.plot(delta)\n",
    "plt.figure()\n",
    "plt.semilogy(delta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we already knew from the model-based class, Policy Iteration converges in a single iteration for this initial policy. Of course, in more complex domains (continuous, large number of states/actions), more refined feature functions will be required. As an exercice, you can try implementing LSPI on the inverted-pendulum domain from OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "326.717px",
    "left": "1134px",
    "top": "67.1333px",
    "width": "159px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
